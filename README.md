# LGBM_Competition
I led a machine learning project called “Richter’s Predictor: Modeling Earthquake Damage” and had the privilege of participating in a live competition where we achieved remarkable success, securing the 3rd position out of 5,873 participants.

In our project, we utilized the LightGBM algorithm and measured our performance using the micro-average F1 score. We conducted a comprehensive comparison of various models, including XGBoost and Random Forest, to identify the most effective approach. Additionally, we employed different feature engineering techniques to enhance our model’s performance.

To optimize our model’s hyperparameters, we utilized Optuna, a powerful tool for hyperparameter tuning, as an alternative to traditional methods like GridSearchCV. Through this process, we discovered the vital role of hyperparameter tuning in achieving exceptional results.

Overall, our project’s findings highlight the significance of hyperparameter tuning and the effectiveness of the LightGBM algorithm and voting classifier, which contributed to our remarkable achievement as one of the top three participants.
